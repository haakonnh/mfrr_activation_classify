{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee06060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: c:\\PythonProjects\\rl_reserve_markets\\.venv1\\Scripts\\python.exe\n",
      "Added to sys.path: True\n",
      "sys.path[0]: C:\\Users\\haako\\AppData\\Local\\Programs\\Python\\Python312\\python312.zip\n",
      "ROOT: c:\\PythonProjects\\rl_reserve_markets\\upreg_classify\n",
      "Data raw exists: True\n",
      "Models dir: c:\\PythonProjects\\rl_reserve_markets\\upreg_classify\\models\n",
      "ROOT: c:\\PythonProjects\\rl_reserve_markets\\upreg_classify\n",
      "Data raw exists: True\n",
      "Models dir: c:\\PythonProjects\\rl_reserve_markets\\upreg_classify\\models\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment & Imports (with path setup)\n",
    "import os, time, json, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Determine project root (parent of notebooks directory)\n",
    "ROOT = Path.cwd().parent  # notebooks -> upreg_classify\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))  # ensure 'src' package import works\n",
    "\n",
    "# Diagnostic: interpreter path\n",
    "print('sys.executable:', sys.executable)\n",
    "# Optional: verify path injection\n",
    "print('Added to sys.path:', str(ROOT) in sys.path)\n",
    "print('sys.path[0]:', sys.path[0])\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "# Import project training entry\n",
    "from src.train.train import train_and_evaluate\n",
    "\n",
    "DATA_RAW = ROOT / 'data' / 'raw'\n",
    "MODELS_DIR = ROOT / 'models'\n",
    "print('ROOT:', ROOT)\n",
    "print('Data raw exists:', DATA_RAW.exists())\n",
    "print('Models dir:', MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bb9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Utility wrapper\n",
    "import importlib\n",
    "from sklearn.metrics import classification_report\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "def reload_all():\n",
    "    \"\"\"Reload key project modules to pick up file changes without restarting VS Code.\"\"\"\n",
    "    print('--- Reloading project modules ---')\n",
    "    import src.data.preprocess as dp\n",
    "    import src.data.features as feat\n",
    "    import src.train.hyperparameters as hp\n",
    "    import src.train.train as tr\n",
    "    importlib.reload(dp)\n",
    "    importlib.reload(feat)\n",
    "    importlib.reload(hp)\n",
    "    importlib.reload(tr)\n",
    "    # Re-export key symbols to current namespace if needed\n",
    "    from src.train.train import train_and_evaluate as _tae\n",
    "    globals()['train_and_evaluate'] = _tae\n",
    "    print('Reloaded: preprocess, features, hyperparameters, train')\n",
    "\n",
    "\n",
    "def run_training(description: str, **kwargs):\n",
    "    \"\"\"Run training via train_and_evaluate and report duration + key metrics.\n",
    "    Required kwargs mirror train_and_evaluate parameters.\n",
    "    This cell focuses on timing + metrics JSON only.\n",
    "    \"\"\"\n",
    "    print(f'=== Run: {description} ===')\n",
    "    start = time.time()\n",
    "    metrics = train_and_evaluate(**kwargs)\n",
    "    dur = time.time() - start\n",
    "    print(f'Completed in {dur:.1f}s')\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def show_classification_reports(metrics: dict, output_dir: str):\n",
    "    \"\"\"Print validation + test classification reports in a separate cell.\n",
    "    Call this after run_training(...) and pass its returned metrics and output_dir.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        label = None\n",
    "        if isinstance(metrics, dict):\n",
    "            label = metrics.get('label') or metrics.get('label_col')\n",
    "        if not (output_dir and label):\n",
    "            print('Missing output_dir or label in metrics; cannot build reports.')\n",
    "            return\n",
    "        pred = TabularPredictor.load(output_dir)\n",
    "        trainer = None\n",
    "        try:\n",
    "            trainer = pred._learner.load_trainer()\n",
    "        except Exception:\n",
    "            trainer = None\n",
    "\n",
    "        # Validation report (if val_data retained)\n",
    "        if trainer is not None and getattr(trainer, 'val_data', None) is not None:\n",
    "            val_data = trainer.val_data\n",
    "            if label in val_data.columns:\n",
    "                y_true_val = val_data[label]\n",
    "                X_val = val_data.drop(columns=[label])\n",
    "                y_pred_val = pred.predict(X_val)\n",
    "                print('Validation classification report:')\n",
    "                print(classification_report(y_true_val, y_pred_val))\n",
    "        else:\n",
    "            print('No validation data available on trainer; skipping val report.')\n",
    "\n",
    "        # Test report: use stored test CSV if train_and_evaluate recorded it\n",
    "        test_csv = None\n",
    "        if isinstance(metrics, dict):\n",
    "            test_csv = metrics.get('test_csv') or metrics.get('test_path')\n",
    "        if test_csv and os.path.exists(test_csv):\n",
    "            import pandas as pd\n",
    "            test_df = pd.read_csv(test_csv)\n",
    "            if label in test_df.columns:\n",
    "                y_true_test = test_df[label]\n",
    "                X_test = test_df.drop(columns=[label])\n",
    "                y_pred_test = pred.predict(X_test)\n",
    "                print('\\nTest classification report:')\n",
    "                print(classification_report(y_true_test, y_pred_test))\n",
    "        else:\n",
    "            if not test_csv:\n",
    "                print('No test_csv/test_path in metrics; skipping test report.')\n",
    "            elif not os.path.exists(test_csv):\n",
    "                print(f'Test CSV path not found: {test_csv}')\n",
    "    except Exception as e:\n",
    "        print('Could not generate classification reports:', e)\n",
    "\n",
    "\n",
    "def base_common(area='NO1'):\n",
    "    return dict(\n",
    "        task='multiclass',\n",
    "        area=area,\n",
    "        data_dir=str(DATA_RAW),\n",
    "        include_2024=True,\n",
    "        heavy_interactions=False,\n",
    "        dropna=True,\n",
    "        train_frac=0.6, val_frac=0.2, test_frac=0.2,\n",
    "        activation_lag_start=4,\n",
    "        single_persistence=True,\n",
    "        weight_factor_up=1.0, weight_factor_down=1.0, weight_factor_none=1.0,\n",
    "        tune_up_bias=True, tune_up_objective='macro',\n",
    "        num_bag_folds=0, num_stack_levels=0,\n",
    "        importance_time_limit=60, importance_subsample=1200, importance_top_n=40,\n",
    "        use_categorical_reglag=False,\n",
    "        data_start=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fbf460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Quick RF/XT priority baseline (NO1)\n",
    "baseline_cfg = base_common(area='NO1')\n",
    "baseline_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'baseline_rf_xt_priority'),\n",
    "    time_limit=500,\n",
    "    presets='best_quality',\n",
    "    model_preset='rf_xt_priority',\n",
    "    hpo_trials=0, hpo_searcher='random', hpo_scheduler='local',\n",
    "))\n",
    "# Uncomment to run\n",
    "# run_training('Baseline RF/XT Priority NO1', **baseline_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d24dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run: CatBoost-only HPO(4) NO1 ===\n"
     ]
    }
   ],
   "source": [
    "# 4. CatBoost-only + 4 HPO trials (NO1)\n",
    "cat_hpo_cfg = base_common(area='NO1')\n",
    "cat_hpo_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'cat_only_hpo4_no_bag'),\n",
    "    time_limit=500,\n",
    "    presets='best_quality',\n",
    "    model_preset='cat_only',\n",
    "    data_start='2025-03-04',\n",
    "    hpo_trials=10, hpo_searcher='random', hpo_scheduler='local',\n",
    "    exclude_persistency_features=True\n",
    "))\n",
    "# Uncomment to run\n",
    "run_training('CatBoost-only HPO(4) NO1', **cat_hpo_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a517d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Baseline RF/XT priority for NO2 (area switch)\n",
    "no2_baseline_cfg = base_common(area='NO2')\n",
    "no2_baseline_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'baseline_rf_xt_priority_NO2'),\n",
    "    time_limit=120,\n",
    "    presets='best_quality',\n",
    "    model_preset='rf_xt_priority',\n",
    "    hpo_trials=0, hpo_searcher='random', hpo_scheduler='local',\n",
    "))\n",
    "# Uncomment to run\n",
    "# run_training('Baseline RF/XT Priority NO2', **no2_baseline_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b083154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Stacking example (rf_xt_boost_stack) with modest time limit\n",
    "stack_cfg = base_common(area='NO1')\n",
    "stack_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'stack_rf_xt_boost'),\n",
    "    time_limit=300,\n",
    "    presets='best_quality',\n",
    "    model_preset='rf_xt_boost_stack',\n",
    "    num_bag_folds=0, num_stack_levels=0,  # keep disabled per requirement\n",
    "    hpo_trials=0,\n",
    "))\n",
    "# Uncomment to run\n",
    "# run_training('Stack Config (no actual bag/stack) NO1', **stack_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb567ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Batch runner: choose which configs to execute in sequence\n",
    "batch = [\n",
    "    # ('Baseline NO1', baseline_cfg),\n",
    "    # ('CatBoost HPO4 NO1', cat_hpo_cfg),\n",
    "    # ('Baseline NO2', no2_baseline_cfg),\n",
    "]\n",
    "results = {}\n",
    "for name, cfg in batch:\n",
    "    metrics = run_training(name, **cfg)\n",
    "    results[name] = metrics\n",
    "if results:\n",
    "    print('Summary (macro F1):', {k: v.get('val_f1_macro') for k, v in results.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c216277",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Increase `time_limit` substantially (e.g., 1800+) for higher quality models.\n",
    "- Set class weighting (e.g., `weight_factor_up=1.3`) to emphasize minority classes.\n",
    "- Enable categorical RegLag features via `use_categorical_reglag=True` if desired.\n",
    "- For persistence across re-runs, choose distinct `output_dir` names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca72d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost-only (no HPO) sanity run\n",
    "xgb_cfg = base_common(area='NO1')\n",
    "xgb_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'xgb_only_baseline_light'),\n",
    "    time_limit=180,\n",
    "    presets='medium_quality',\n",
    "    model_preset='xgb_only',\n",
    "    hpo_trials=0,               # disable HPO to isolate training\n",
    "    hpo_searcher='random',\n",
    "    hpo_scheduler='local',\n",
    "    #data_start='2025-06-01',    # keep subset for speed\n",
    "))\n",
    "run_training('XGBoost-only BASELINE NO1 LIGHT', **xgb_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06930da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. XGBoost-only FULL run (fixed variants, full data)\n",
    "xgb_full_cfg = base_common(area='NO1')\n",
    "xgb_full_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'xgb_only_full_fixed_actual'),\n",
    "    time_limit=1800,             # 30 minutes budget; adjust as needed\n",
    "    presets='best_quality',\n",
    "    model_preset='xgb_only_fixed',\n",
    "    hpo_trials=0,                # no HPO; use fixed variants\n",
    "    hpo_searcher='random',\n",
    "    hpo_scheduler='local',\n",
    "    data_start=None,             # ensure full dataset\n",
    "))\n",
    "run_training('XGBoost-only FULL FIXED VARIANTS NO1', **xgb_full_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Inspect trained model families from saved predictors\n",
    "from autogluon.tabular import TabularPredictor\n",
    "paths = [\n",
    "    MODELS_DIR / 'xgb_only_full_fixed',\n",
    "    MODELS_DIR / 'xgb_only_full_fixed_actual',\n",
    "    MODELS_DIR / 'xgb_only_full_hpo6',\n",
    "    MODELS_DIR / 'xgb_only_full_hpo2_quick',\n",
    "]\n",
    "for p in paths:\n",
    "    p = str(p)\n",
    "    if Path(p).exists():\n",
    "        try:\n",
    "            pred = TabularPredictor.load(p)\n",
    "            print(f'Path: {p}')\n",
    "            print('Models:', pred.model_names())\n",
    "        except Exception as e:\n",
    "            print(f'Failed to load {p}:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d1a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Force-reload training modules to pick up latest hyperparameter presets\n",
    "import importlib\n",
    "import src.train.hyperparameters as hp\n",
    "import src.train.train as tr\n",
    "hp = importlib.reload(hp)\n",
    "tr = importlib.reload(tr)\n",
    "from src.train.hyperparameters import build_hyperparameters\n",
    "print('xgb_only_fixed keys:', list(build_hyperparameters('xgb_only_fixed', hpo_trials=0).keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Sanity: XGBoost-only FIXED on subset, verify model families\n",
    "xgb_subset_cfg = base_common(area='NO1')\n",
    "xgb_subset_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'xgb_only_fixed_subset_check'),\n",
    "    time_limit=1000,\n",
    "    presets='best_quality',\n",
    "    model_preset='xgb_only_fixed',\n",
    "    hpo_trials=5,\n",
    "    data_start='2025-03-04',\n",
    "))\n",
    "metrics = run_training('XGB FIXED SUBSET CHECK', **xgb_subset_cfg)\n",
    "# Show trained models\n",
    "pred = TabularPredictor.load(xgb_subset_cfg['output_dir'])\n",
    "print('Models:', pred.model_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12899bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Sanity: CatBoost-only on subset, mirror cfg of #12\n",
    "from src.train.train import train_and_evaluate\n",
    "reload_all()\n",
    "cat_subset_cfg = base_common(area='NO1')\n",
    "cat_subset_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'cat_only_subset_check'),\n",
    "    time_limit=600,\n",
    "    presets='best_quality',\n",
    "    model_preset='cat_only',\n",
    "    hpo_trials=2,\n",
    "    data_start='2025-03-04',\n",
    "))\n",
    "metrics = run_training('CAT ONLY SUBSET CHECK', **cat_subset_cfg)\n",
    "# Show trained models\n",
    "pred = TabularPredictor.load(cat_subset_cfg['output_dir'])\n",
    "print('Models:', pred.model_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Sanity: LightGBM-only on subset, mirror cfg of #12\n",
    "lgbm_subset_cfg = base_common(area='NO1')\n",
    "lgbm_subset_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'lgbm_only_subset_check'),\n",
    "    time_limit=1000,\n",
    "    presets='best_quality',\n",
    "    model_preset='lgbm_only',\n",
    "    hpo_trials=0,\n",
    "    data_start='2025-03-04',\n",
    "))\n",
    "metrics = run_training('LGBM ONLY SUBSET CHECK', **lgbm_subset_cfg)\n",
    "# Show trained models\n",
    "pred = TabularPredictor.load(lgbm_subset_cfg['output_dir'])\n",
    "print('Models:', pred.model_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Subset run with persistency interactions disabled (XGB fixed)\n",
    "xgb_no_inter_subset_cfg = base_common(area='NO1')\n",
    "xgb_no_inter_subset_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'xgb_fixed_subset_no_interactions'),\n",
    "    time_limit=600,\n",
    "    presets='medium_quality',\n",
    "    model_preset='xgb_only_fixed',\n",
    "    hpo_trials=0,\n",
    "    data_start='2025-03-04',\n",
    "    disable_persistency_interactions=True,\n",
    "))\n",
    "metrics = run_training('XGB FIXED SUBSET NO INTERACTIONS', **xgb_no_inter_subset_cfg)\n",
    "# Show trained models\n",
    "pred = TabularPredictor.load(xgb_no_inter_subset_cfg['output_dir'])\n",
    "print('Models:', pred.model_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. LightGBM-only HPO on subset (verify only GBM models)\n",
    "lgbm_hpo_subset_cfg = base_common(area='NO1')\n",
    "lgbm_hpo_subset_cfg.update(dict(\n",
    "    output_dir=str(MODELS_DIR / 'lgbm_only_subset_hpo'),\n",
    "    time_limit=900,\n",
    "    presets='best_quality',\n",
    "    model_preset='lgbm_only',\n",
    "    hpo_trials=4,\n",
    "    hpo_searcher='random',\n",
    "    hpo_scheduler='local',\n",
    "    data_start='2025-03-04',\n",
    "))\n",
    "metrics = run_training('LGBM ONLY HPO(4) SUBSET CHECK', **lgbm_hpo_subset_cfg)\n",
    "# Show trained models\n",
    "pred = TabularPredictor.load(lgbm_hpo_subset_cfg['output_dir'])\n",
    "print('Models:', pred.model_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7eb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Inspect features after persistency-interactions disabled run\n",
    "# Load predictor from cell #15 output_dir and list any Persistency interaction features\n",
    "from autogluon.tabular import TabularPredictor\n",
    "p = TabularPredictor.load(xgb_no_inter_subset_cfg['output_dir'])\n",
    "feat_names = []\n",
    "try:\n",
    "    feat_names = list(p.feature_metadata.get_features())\n",
    "except Exception:\n",
    "    try:\n",
    "        feat_names = list(p._learner.feature_metadata_in.get_features())\n",
    "    except Exception:\n",
    "        try:\n",
    "            feat_names = list(p._learner.features)\n",
    "        except Exception:\n",
    "            feat_names = []\n",
    "print('Total features:', len(feat_names))\n",
    "bad = [f for f in feat_names if (' x Persistency' in f) or ('Persistency x ' in f) or (' x PersistencyDown' in f) or ('PersistencyDown x ' in f)]\n",
    "print('Persistency-interaction features found:', bad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
